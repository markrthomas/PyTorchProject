{"cells":[{"cell_type":"markdown","source":["\n","Summary Report:\n","\n","Do this as a straight vision classification with a pretrained CNN to start.\n","\n","Hi, this is my project for CapStone. I am reading in a previously unused AI raw data set of forrest JPG pictures from drones to look for bark beatle kill and spread over time. This is too large for this class project so I'm only doing the reading in of data and tree classification as a first step. I also have annotated box data to go along with the pictures in XML format.\n","\n","This is the overall plan:\n","  1) read in the compressed datafile, decompress in a local space and use the data in the format specified. (not done) currently using decompressed data in my own personal google drive area (will fix to make readable by everyone)\n","\n","  2) split up data to train (in process)\n","  3) use VGG16 to pipe clean my code (in process)\n","  3a) work in the annotated data to speed up train/classify\n","  4) replace VGG16 with my model (not done)\n","  5) use pretrianed weights (not done)\n","  6) benchmark VGG16 and compare to my model (not done)\n","\n","\n","  Still have a way to go here!\n"],"metadata":{"id":"ujUWAMDlPW8h"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"yrzZRul42zJs","outputId":"2e8b0ab4-7926-4a60-c922-a87b13b36acb","executionInfo":{"status":"error","timestamp":1687456320717,"user_tz":360,"elapsed":2020,"user":{"displayName":"Mark Thomas","userId":"15077687351252792306"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","CNNClassifier(\n","  (pipeline): Sequential(\n","    (0): Dropout(p=0.2, inplace=False)\n","    (1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (2): ReLU()\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): Flatten(start_dim=1, end_dim=-1)\n","    (8): Linear(in_features=12544, out_features=10, bias=True)\n","  )\n",")\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-dcfdc019c801>\u001b[0m in \u001b[0;36m<cell line: 306>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExponentialLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0mdataset_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object does not support item assignment"]}],"source":["\n","\n","# We are in the hack/pipe clean phase of the project\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torchvision\n","import torchvision.datasets\n","import torchvision.datasets as datasets\n","import torch.utils.data as data\n","from torchvision import models as models\n","from torchvision import transforms\n","from torch.utils.data import Subset\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.modules.flatten import Flatten\n","from PIL import Image\n","import time, copy\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as metrics\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# device config (train our model on GPU if it is available which is much faster)\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device = torch.device('cpu')\n","device\n","\n","# These transforms will be performed on every datapoint - in this example we want to transform every\n","# datapoint to a Tensor datatype, and perform normalization\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n","\n","\n","\"\"\"\n","# Notice how FashionMNIST is also built into PyTorch!\n","fashion_mnist_train = torchvision.datasets.FashionMNIST('', train=True, transform =transform, download=True)\n","# We will split out train dataset into train and validation!\n","fashion_mnist_train, fashion_mnist_val = torch.utils.data.random_split(fashion_mnist_train, [int(np.floor(len(fashion_mnist_train)*0.75)), int(np.ceil(len(fashion_mnist_train)*0.25))])\n","fashion_mnist_test = torchvision.datasets.FashionMNIST('', train=False, transform = transform, download=True)\n","\"\"\"\n","\n","# Define the dataset\n","class MyDataset(datasets.ImageFolder):\n","    def __init__(self, url):\n","        super().__init__(url)\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.imgs[idx]).convert('RGB')\n","        label = self.labels[idx]\n","        return img, label\n","\n","\n","# Load the dataset\n","# dataset = MyDataset('https://www.kaggle.com/datasets/tanchu/data-set-spruce-bark-beetle?resource=download')\n","directory = \"/content/gdrive/My Drive/MiT_DataSets/Data_Set_Spruce_Bark_Beetle/\"\n","dataset = MyDataset(directory)\n","\n","# Create a data loader\n","data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","\n","\n","\n","\"\"\"\n","# Load the dataset\n","dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n","\n","# Create a data loader\n","data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, transform=transforms.ToTensor())\n","# train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n","\n","# Iterate over the data loader\n","for i, (images, labels) in enumerate(data_loader):\n","  # Do something with the images and labels\n","  print(images.shape)\n","  print(labels.shape)\n","\"\"\"\n","\n","\"\"\" # another version\n","# Define the dataset\n","class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, root, transform=None):\n","        self.root = root\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(os.listdir(self.root))\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.root, str(idx) + '.jpg')\n","        img = Image.open(img_path).convert('RGB')\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img\n","\n","# Create the dataloader\n","dataloader = DataLoader(MyDataset(root='./data/test'), batch_size=32, shuffle=True)\n","\n","# Convert the images to tensors\n","for img in dataloader:\n","    img_tensor = torch.tensor(img)\n","\"\"\"\n","\n","\n","\n","\"\"\"\n","# Iterate over the data loader\n","for imgs, labels in data_loader:\n","    # Do something with the images and labels\n","\"\"\"\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, directory):\n","        self.directory = directory\n","        self.images = []\n","        for filename in os.listdir(directory):\n","            if filename.endswith(\".jpg\"):\n","                self.images.append(os.path.join(directory, filename))\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.images[index])\n","        image = image.resize((224, 224))\n","        image = image.convert(\"RGB\")\n","        image = torch.tensor(image)\n","        return image\n","\n","dataloader = data_loader\n","\n","\n","\n","# We will create DataLoaders just like before with a batch size of 100\n","batch_size = 100\n","\n","\"\"\"\n","dataloaders = {'train': DataLoader(data_train, batch_size=batch_size),\n","               'val': DataLoader(data_val, batch_size=batch_size),\n","               'test': DataLoader(data_test, shuffle=True, batch_size=batch_size)}\n","\n","dataset_sizes = {'train': len(data_train),\n","                 'val': len(data_val),\n","                 'test': len(data_test)}\n","\n","print(f'dataset_sizes = {dataset_sizes}')\n","\n","# plot a digit ground truth and autoencoding\n","def view_data_set(label, count = 1):\n","    fig = plt.figure()\n","    idx = 1\n","    for inputs, labels in dataloaders[\"test\"]:\n","        for i, input in enumerate(inputs):\n","            # we only want to view a certain class\n","            if (labels[i] != label):\n","                continue\n","            # plot the ground truth\n","            ax = fig.add_subplot(1, count, idx)\n","            input = input.cpu().detach().numpy().reshape((28,28))\n","            ax.imshow(input, cmap='gray')\n","            idx += 1\n","            if idx > count:\n","                break\n","        if idx > count:\n","            break\n","view_data_set(8, 6)\n","view_data_set(7, 1)\n","\"\"\"\n","\n","## Your Turn\n","# Hint! Create a CNNClassifier class that implements a forward function\n","# TODO: replace this with the model with the extra layer!!\n","\n","'''\n","Please submit ipynb code not pdfs! Your architectures a bit odd, maxpools definitely don't belong after flattening!\n","You also use them too liberally, you typically have 2-3 conv layers then a max pool.\n","You also need to regularise the gradient better this is done via batchnorms after the convolutional and max pool layers.\n","No need for softmax as its included in the CrossEntropy loss. You also have 2 linear layers consecutively\n"," (which isn't a FC layer, you require a non-linear layer between to get the benefit of compute)\n","\n","'''\n","# Model:\n","\n","class CNNClassifier(nn.Module):\n","    def __init__(self):\n","        super(CNNClassifier, self).__init__()\n","        # Split the Encoder and Decoder\n","\n","        self.pipeline = nn.Sequential(\n","            nn.Dropout(0.20),\n","            # Extra pooling didn't help\n","            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","           # nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1), # Still too wide, didn't help really ..\n","           # nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2),\n","            nn.BatchNorm2d(64), # Batch Norm did help smooth things out ..\n","           # nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1), # Too wide, didn't help..\n","           # Extra Conv layers didn't help.. & slowed things way down\n","            nn.Flatten(),\n","            nn.Linear(12544, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.pipeline(x)\n","\n","#TODO fix and adjust\n","learning_rate = 0.001 # was 0.001\n","num_epochs = 10 # was 10\n","\n","model = CNNClassifier().to(device)\n","print(model)\n","\n","\n","#TODO: replace this with the last model trainer in example!\n","# Hint! Try reusing one of the training functions we have previously written\n","\n","def train_classification_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict()) # keep the best weights stored separately\n","    best_acc = 0.0\n","    best_epoch = 0\n","\n","    # Each epoch has a training, validation, and test phase\n","    phases = ['train', 'val', 'test']\n","\n","    # Keep track of how loss and accuracy evolves during training\n","    training_curves = {}\n","    for phase in phases:\n","        training_curves[phase+'_loss'] = []\n","        training_curves[phase+'_acc'] = []\n","\n","    for epoch in range(num_epochs):\n","        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                # No need to flatten the inputs!\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, predictions = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + update weights only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(predictions == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            training_curves[phase+'_loss'].append(epoch_loss)\n","            training_curves[phase+'_acc'].append(epoch_acc)\n","\n","            print(f'{phase:5} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # deep copy the model if it's the best accuracy (bas\n","            if phase == 'val' and epoch_acc > best_acc:\n","              best_epoch = epoch\n","              best_acc = epoch_acc\n","              best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    time_elapsed = time.time() - since\n","    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f} at epoch {best_epoch}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, training_curves\n","\n","\n","\n","# loss and optimizer\n","criterion = nn.CrossEntropyLoss() # CrossEntropyLoss for classification!\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","\n","dataloaders[0] = data_loader\n","dataset_sizes = [10,10,10] # to test\n","\n","# Train the model. We also will store the results of training to visualize\n","model, training_curves = train_classification_model(model, dataloaders, dataset_sizes,\n","                                     criterion, optimizer, scheduler, num_epochs=num_epochs)\n","\n","\n","### Visualizing Training Curves and Results\n","# Utility functions for plotting your results!\n","def plot_training_curves(training_curves,\n","                         phases=['train', 'val', 'test'],\n","                         metrics=['loss','acc']):\n","    epochs = list(range(len(training_curves['train_loss'])))\n","    for metric in metrics:\n","        plt.figure()\n","        plt.title(f'Training curves - {metric}')\n","        for phase in phases:\n","            key = phase+'_'+metric\n","            if key in training_curves:\n","                if metric == 'acc':\n","                    plt.plot(epochs, [item.detach().cpu() for item in training_curves[key]])\n","                else:\n","                    plt.plot(epochs, training_curves[key])\n","        plt.xlabel('epoch')\n","        plt.legend(labels=phases)\n","\n","\n","def classify_predictions(model, device, dataloader):\n","    model.eval()   # Set model to evaluate mode\n","    all_labels = torch.tensor([]).to(device)\n","    all_scores = torch.tensor([]).to(device)\n","    all_preds = torch.tensor([]).to(device)\n","    for inputs, labels in dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = torch.softmax(model(inputs),dim=1)\n","        _, preds = torch.max(outputs, 1)\n","        # scores = outputs[:,1]\n","        scores = outputs[::]\n","        all_labels = torch.cat((all_labels, labels), 0)\n","        all_scores = torch.cat((all_scores, scores), 0)\n","        all_preds = torch.cat((all_preds, preds), 0)\n","    return all_preds.detach().cpu(), all_labels.detach().cpu(), all_scores.detach().cpu()\n","\n","\n","# Some code from my system to try\n","\n","import os\n","import torch\n","import numpy as np\n","import torchvision\n","from PIL import Image\n","from torchvision import transforms\n","from torchvision import models as models\n","\n","trans = transforms.Compose([transforms.ToTensor()])\n","\n","# image = torchvision.io.read_image(\"./data/test_tree_vert.jpg\")\n","image = \"./data/test_tree_vert.jpg\"\n","img = Image.open(image)\n","# print(image)\n","\n","# resized_image = transforms.Resize((224, 224), antialias=None)(image)\n","# print(resized_image)\n","\n","my_ten = trans(img)\n","\n","print(my_ten)\n","\n","image_path = \"./data/Data_Set_Spruce_Bark_Beetle/oblique/Backsjon_20201016_oblique/Images/\"\n","\n","# Load the images\n","images = []\n","file_list = os.listdir(image_path)\n","for file in file_list[:1]:\n","    img = Image.open(image_path+file)\n","    # img.thumbnail((256,256))\n","    # img.show()\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    )\n","])\n","\n","img = transform(img)\n","img = img.unsqueeze(0)\n","img_tensor = torch.from_numpy(np.array(img))\n","\n","# img_tensor = torch.from_numpy(np.array(img))\n","# transform = transforms.ToTensor()\n","# img_tensor = transform(img)\n","\n","# Load the model\n","model = torchvision.models.vgg16()\n","print(model)\n","\n","# reshape the tensor\n","# tensr = torch.reshape(img_tensor, (512,))\n","\n","# reshape the tensor to match the size needed for vgg16\n","# tensr = torchvision.transforms.Resize(input_size)(img_tensor)\n","\n","# Make a prediction\n","# prediction = model(tensr)\n","prediction = model(img)\n","\n","\n","# Prepare the training data.\n","# train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n","train_data = img\n","\n","# Define the loss function and optimizer.\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","\n","\n","# Train the model.\n","for epoch in range(10):\n","    for batch in train_data:\n","        print(batch)\n","        print(batch.size())\n","        inputs, labels = batch\n","        predictions = model(inputs)\n","        loss = loss_function(predictions, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","# Evaluate the model.\n","test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n","correct = 0\n","total = 0\n","for batch in test_data:\n","    inputs, labels = batch\n","    predictions = model(inputs)\n","    _, predicted = torch.max(predictions.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","print('Accuracy: {}'.format(correct / total))\n","\n","\n","\n","\n","# too many images here for my machine ..\n","for image in os.listdir(image_path):\n","  image = Image.open(os.path.join(image_path, image))\n","  image = transforms.ToTensor()(image)\n","  images.append(image)\n","\n","# Convert the images to tensors\n","images = torch.stack(images)\n","\n","print(images.size())\n","exit\n","\n","class ZipDataset(Dataset):\n","\n","    def __init__(self, zip_file, transform=None):\n","        self.zip_file = zip_file\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.zip_file.namelist())\n","\n","    def __getitem__(self, index):\n","        with zipfile.ZipFile(self.zip_file) as zip_file:\n","            file_name = zip_file.namelist()[index]\n","            file_path = os.path.join(self.zip_file.namelist(), file_name)\n","            data = torch.load(file_path)\n","            if self.transform is not None:\n","                data = self.transform(data)\n","        return data\n","\n","\n","# Load the image\n","#images = ImageFolder(root=image_path).load_sample()\n","images = ImageFolder(root=image_path)\n","# Load the images\n","#images = [Image.open(image_path) for image_path in image_paths]\n","# images = Image.open(image_path)\n","\n","# Convert the images to tensors\n","transform = transforms.ToTensor()\n","images = [transform(image) for image in images]\n","\n","# Check the shapes of the tensors\n","print(images[0].shape)\n","print(images[1].shape)\n","print(images[2].shape)\n","\n","# Convert the image to a tensor\n","image = ToTensor()(image)\n","\n","# Normalize the image\n","image = Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])(image)\n","\n","# Create an annotator\n","annotator = ImageAnnotator(image)\n","\n","# Add a bounding box\n","annotator.add_bounding_box(image, [100, 100, 200, 200])\n","\n","# Save the annotations\n","# TODO: fix this\n","# annotator.save(\"annotations.json\")\n","\n","\n","def plot_cm(model, device, dataloaders, phase='test'):\n","    class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    preds, labels, scores = classify_predictions(model, device, dataloaders[phase])\n","\n","    cm = metrics.confusion_matrix(labels, preds)\n","    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","    ax = disp.plot().ax_\n","    ax.set_title('Confusion Matrix -- counts')\n","\n","\n","plot_training_curves(training_curves, phases=['train', 'val', 'test'])\n","\n","res = plot_cm(model, device, dataloaders, phase='test')\n"]},{"cell_type":"markdown","metadata":{"id":"1pCcLS4Vw0-F"},"source":["## Conclusions\n","\n","Now that we have implemented our network we want to examine the results.\n","\n","What class of object is most often misclassified? What class is it incorrectly classified as most often?\n","\n","Additionally, try re-training your network with dropout included. Does this help the performance or is there a noticeable change in the ability of the model to generalize? Is the most commonly misclassified object still the same as with no dropout?"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1xnzR5-tflHyMGksyvxCZnqlNG_gKYG-J","timestamp":1686677186013},{"file_id":"1A2xTJlakL-1ErnS4PdpFVpKoW2PAFbx6","timestamp":1684563465310},{"file_id":"1QIIhUQ75ANE4w8i2BJe9Wi2Rqw4ojgQl","timestamp":1655810701312},{"file_id":"1zG4bF3pgxTGZ5hbdG99HSQsrmQYXD4o3","timestamp":1655777060348}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}